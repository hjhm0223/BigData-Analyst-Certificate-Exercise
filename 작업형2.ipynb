{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a945fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0       1\n",
      "0             alabaster  0.7.12\n",
      "1       anaconda-client   1.7.2\n",
      "2    anaconda-navigator   2.0.3\n",
      "3      anaconda-project   0.9.1\n",
      "4                 anyio   2.2.0\n",
      "..                  ...     ...\n",
      "250                yapf  0.31.0\n",
      "251                zict   2.0.0\n",
      "252                zipp   3.4.1\n",
      "253          zope.event   4.5.0\n",
      "254      zope.interface   5.3.0\n",
      "\n",
      "[255 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources \n",
    "import pandas as pd\n",
    "OutputDataSet = pd.DataFrame(sorted([(i.key, i.version) for i in pkg_resources.working_set])) \n",
    "print(OutputDataSet)\n",
    "\n",
    "# 전체 칼럼 출력하기\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fd7f5",
   "metadata": {},
   "source": [
    "## 1.  고객 3500명에 대한 학습용 데이터를 이용하여 성별 예측 모형을 만든 후, 평가용 데이터에 적용하여 얻은 예측값(남자일 확률)을 csv 파일로 생성. 데이터 전처리, Feature Engineering, 분류 알고리즘 사용, 하이퍼 파라미터 최적화, 모형 앙상블 등이 수반\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 불러오기\n",
    "x_train = pd.read_csv('./bigData/x_train.csv', encoding='CP949')\n",
    "y_train = pd.read_csv('./bigData/y_train.csv', encoding='CP949')\n",
    "x_test = pd.read_csv('./bigData/x_test.csv', encoding='CP949')\n",
    "\n",
    "## 데이터 탐색\n",
    "x_train.shape, y_train.shape, x_test.shape\n",
    "x_train.head()\n",
    "x_train.info()\n",
    "x_train.describe().T\n",
    "x_train.isnull().sum()\n",
    "x_test.isnull().sum()\n",
    "\n",
    "## 데이터 전처리\n",
    "### 불필요한 칼럼 삭제\n",
    "x_test_cust_id = x_test['cust_id']\n",
    "x_train = x_train.drop(columns = ['cust_id'])\n",
    "y_train = y_train.drop(columns = ['cust_id'])\n",
    "x_test = x_test.drop(columns = ['cust_id'])\n",
    "\n",
    "### 결측값 처리\n",
    "x_train['환불금액'] = x_train['환불금액'].fillna(0)\n",
    "x_test['환불금액'] = x_test['환불금액'].fillna(0)\n",
    "\n",
    "### 범주형 칼럼 Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "x_train['주구매상품'] = encoder.fit_transform(x_train['주구매상품'])\n",
    "x_test['주구매상품'] = encoder.fit_transform(x_test['주구매상품'])\n",
    "encoder.classes_\n",
    "x_train['주구매지점'] = encoder.fit_transform(x_train['주구매지점'])\n",
    "x_test['주구매지점'] = encoder.fit_transform(x_test['주구매지점'])\n",
    "encoder.classes_\n",
    "\n",
    "### 파생변수 만들기\n",
    "x_train.loc[x_train['환불금액'] > 0, '환불금액_NEW'] = 1\n",
    "x_train.loc[x_train['환불금액'] == 0, '환불금액_NEW'] = 0\n",
    "x_test.loc[x_test['환불금액'] > 0, '환불금액_NEW'] = 1\n",
    "x_test.loc[x_test['환불금액'] == 0, '환불금액_NEW'] = 0\n",
    "\n",
    "x_train = x_train.drop(columns = ['환불금액'])\n",
    "x_test = x_test.drop(columns = ['환불금액'])\n",
    "\n",
    "### 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns = x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.fit_transform(x_test), columns = x_test.columns)\n",
    "\n",
    "### 상관관계확인\n",
    "x_train[['총구매액', '최대구매액', '환불금액_NEW']].corr()\n",
    "x_train = x_train.drop(columns = ['최대구매액'])\n",
    "x_test = x_test.drop(columns = ['최대구매액'])\n",
    "\n",
    "## 데이터 학습 및 평가\n",
    "### 데이터 학습\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "pd.DataFrame(y_test_pred)\n",
    "\n",
    "### 결과 예측\n",
    "y_test_proba = model.predict_proba(x_test)\n",
    "y_test_proba_man = pd.DataFrame(y_test_proba)[1]\n",
    "\n",
    "## 모델 평가\n",
    "y_train_pred = model.predict(x_train)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "## 결과 저장\n",
    "result = pd.concat([x_test_cust_id, y_test_proba_man], axis=1)\n",
    "result.columns = ['cust_id', 'gender']\n",
    "result.to_csv('./bigData/result1.csv', index=False)\n",
    "result_test = pd.read_csv('./bigData/result1.csv')\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74829f7",
   "metadata": {},
   "source": [
    "## 2. 고객 891명에 대한 학습용 데이터를 이용하여 생존 여부를 예측하는 모형을 만든다. 이후 예측 모형을 평가용 데이터에 적용하여 418명 승객의 생존 여부 예측값을 CSV 파일로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76c3d573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Passenger  Survived\n",
      "0          892         1\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "..         ...       ...\n",
      "413       1305         0\n",
      "414       1306         1\n",
      "415       1307         0\n",
      "416       1308         0\n",
      "417       1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-2fef2c753597>:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "### 데이터 불러오기\n",
    "x_train = pd.read_csv('./bigData/titanic_x_train.csv', encoding='CP949')\n",
    "x_test = pd.read_csv('./bigData/titanic_x_test.csv', encoding='CP949')\n",
    "y_train = pd.read_csv('./bigData/titanic_y_train.csv', encoding='CP949')\n",
    "\n",
    "### 데이터 탐색 \n",
    "y_train.columns = ['PassengerId', 'Survived']\n",
    "# print(x_train.head(), x_test.head(), y_train.head())\n",
    "# print(x_train.info(), x_test.info(), y_train.info())\n",
    "pd.concat([x_train, y_train['Survived']], axis=1).corr()['Survived']\n",
    "\n",
    "### 데이터 정제\n",
    "x_train = x_train.drop(columns = ['PassengerId', '나이', '승객이름', '티켓번호', '객실번호'])\n",
    "x_test_passengerId = x_test['PassengerId']\n",
    "x_test = x_test.drop(columns = ['PassengerId', '나이', '승객이름', '티켓번호', '객실번호'])\n",
    "y_train = y_train.drop(columns = ['PassengerId'])\n",
    "\n",
    "# print(x_train['선착장'].mode())\n",
    "\n",
    "x_train['선착장'] = x_train['선착장'].fillna('S')\n",
    "x_test['운임요금'] = x_test['운임요금'].fillna(x_test['운임요금'].mean())\n",
    "\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isnull().sum())\n",
    "\n",
    "x_train['성별'] = x_train['성별'].replace('male', 0).replace('female', 0)\n",
    "x_test['성별'] = x_test['성별'].replace('male', 0).replace('female', 0)\n",
    "\n",
    "x_train_선착장 = pd.get_dummies(x_train['선착장'], drop_first = True).rename(columns = {'Q': '선착장Q', 'S': '선착장S'})\n",
    "x_train = pd.concat([x_train, x_train_선착장], axis=1)\n",
    "x_train = x_train.drop(columns = ['선착장'])\n",
    "x_test_선착장 = pd.get_dummies(x_test['선착장'], drop_first = True).rename(columns = {'Q': '선착장Q', 'S': '선착장S'})\n",
    "x_test = pd.concat([x_test, x_test_선착장], axis=1)\n",
    "x_test = x_test.drop(columns = ['선착장'])\n",
    "\n",
    "x_train['가족수'] = x_train['형제자매배우자수']+x_train['부모자식수']\n",
    "x_test['가족수'] = x_test['형제자매배우자수']+x_test['부모자식수']\n",
    "x_train = x_train.drop(columns = ['형제자매배우자수', '부모자식수'])\n",
    "x_test = x_test.drop(columns = ['형제자매배우자수', '부모자식수'])\n",
    "\n",
    "#x_train.head()\n",
    "\n",
    "### 데이터 모델링\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred = pd.DataFrame(model.predict(x_test))\n",
    "\n",
    "### 모델 평가\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_train_pred = model.predict(x_train)\n",
    "roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "### 결과 저장\n",
    "result = pd.concat([x_test_passengerId, y_test_pred], axis=1)\n",
    "result.columns = ['Passenger', 'Survived']\n",
    "result.to_csv('./bigData/result2.csv', index = False)\n",
    "print(pd.read_csv('./bigData/result2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56d96084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Binarizer', 'FunctionTransformer', 'KBinsDiscretizer', 'KernelCenterer', 'LabelBinarizer', 'LabelEncoder', 'MaxAbsScaler', 'MinMaxScaler', 'MultiLabelBinarizer', 'Normalizer', 'OneHotEncoder', 'OrdinalEncoder', 'PolynomialFeatures', 'PowerTransformer', 'QuantileTransformer', 'RobustScaler', 'StandardScaler', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_csr_polynomial_expansion', '_data', '_discretization', '_encoders', '_function_transformer', '_label', 'add_dummy_feature', 'binarize', 'label_binarize', 'maxabs_scale', 'minmax_scale', 'normalize', 'power_transform', 'quantile_transform', 'robust_scale', 'scale']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "print(dir(sklearn.preprocessing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139a5c5",
   "metadata": {},
   "source": [
    "## 3. 고객 10866건에 대한 학습용 데이터를 이용하여 자전거 대여량 예측 모형을 만든다. 생성한 예측 모형으로 평가용 데이터에 해당하는 6493건의 자전거 대여량 예측값을 CSV 파일로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28d17a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999077799610809\n",
      "              datetime  count\n",
      "0      2011-01-20 0:00    5.0\n",
      "1      2011-01-20 1:00    5.0\n",
      "2      2011-01-20 2:00    3.0\n",
      "3      2011-01-20 3:00    2.0\n",
      "4      2011-01-20 4:00    2.0\n",
      "...                ...    ...\n",
      "6488  2012-12-31 19:00  262.0\n",
      "6489  2012-12-31 20:00  214.0\n",
      "6490  2012-12-31 21:00   98.0\n",
      "6491  2012-12-31 22:00   98.0\n",
      "6492  2012-12-31 23:00   54.0\n",
      "\n",
      "[6493 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "### 데이터 불러오기\n",
    "x_train = pd.read_csv('./bigData/bike_x_train.csv', encoding='CP949')\n",
    "x_test = pd.read_csv('./bigData/bike_x_test.csv', encoding='CP949')\n",
    "y_train = pd.read_csv('./bigData/bike_y_train.csv', encoding='CP949')\n",
    "y_train.columns = ['datetime', 'count']\n",
    "\n",
    "### 데이터 탐색\n",
    "# print(x_train.head())\n",
    "# print(x_test.head())\n",
    "# print(y_train.head())\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# print(y_train.info())\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isnull().sum())\n",
    "# print(y_train.isnull().sum())\n",
    "\n",
    "### 데이터 정제\n",
    "x_train['year'] = pd.to_datetime(x_train['datetime']).dt.year\n",
    "x_train['month'] = pd.to_datetime(x_train['datetime']).dt.month\n",
    "x_train['day'] = pd.to_datetime(x_train['datetime']).dt.day\n",
    "x_train['hour'] = pd.to_datetime(x_train['datetime']).dt.hour\n",
    "x_test['year'] = pd.to_datetime(x_test['datetime']).dt.year\n",
    "x_test['month'] = pd.to_datetime(x_test['datetime']).dt.month\n",
    "x_test['day'] = pd.to_datetime(x_test['datetime']).dt.day\n",
    "x_test['hour'] = pd.to_datetime(x_test['datetime']).dt.hour\n",
    "\n",
    "x_test_datetime = x_test['datetime']\n",
    "x_train = x_train.drop(columns = ['datetime', 'day'])\n",
    "x_test = x_test.drop(columns = ['datetime', 'day'])\n",
    "y_train = y_train.drop(columns = ['datetime'])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns = x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.fit_transform(x_test), columns = x_test.columns)\n",
    "\n",
    "### 데이터 학습\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(x_train, y_train)\n",
    "# y_test_pred = pd.DataFrame(model.predict(x_test))\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred = pd.DataFrame(model.predict(x_test))\n",
    "\n",
    "# print(y_test_pred.head())\n",
    "\n",
    "### 모델 평가 \n",
    "from sklearn.metrics import roc_auc_score, f1_score, r2_score\n",
    "y_train_pred = model.predict(x_train)\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "\n",
    "### 결과 저장\n",
    "result = pd.concat([x_test_datetime, y_test_pred], axis=1)\n",
    "result.columns = ['datetime', 'count']\n",
    "result.to_csv('./bigData/result3.csv', index = False)\n",
    "print(pd.read_csv('./bigData/result3.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b9580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
